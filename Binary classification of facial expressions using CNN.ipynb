{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Each image shape is:(1690, 1067, 3)\n",
      "The maximum pixel value used is:255.0\n",
      "Found 164 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step - accuracy: 0.5971 - loss: 2.4275\n",
      "Epoch 2/20\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 68ms/step - accuracy: 0.6145 - loss: 0.7336\n",
      "Epoch 3/20\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 67ms/step - accuracy: 0.5330 - loss: 0.6772\n",
      "Epoch 4/20\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - accuracy: 0.6099 - loss: 0.5962\n",
      "Epoch 5/20\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 61ms/step - accuracy: 0.7945 - loss: 0.4529\n",
      "Epoch 6/20\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - accuracy: 0.8793 - loss: 0.2907\n",
      "Epoch 7/20\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 57ms/step - accuracy: 0.8405 - loss: 0.3758\n",
      "Epoch 8/20\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 68ms/step - accuracy: 0.9305 - loss: 0.1871\n",
      "Epoch 9/20\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 62ms/step - accuracy: 0.9648 - loss: 0.0904\n",
      "Epoch 10/20\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 71ms/step - accuracy: 0.9483 - loss: 0.1812\n",
      "Epoch 11/20\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 70ms/step - accuracy: 0.9899 - loss: 0.0981\n",
      "Epoch 12/20\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 71ms/step - accuracy: 0.9981 - loss: 0.0266\n",
      "Epoch 13/20\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - accuracy: 0.9996 - loss: 0.0186\n",
      "Epoch 14/20\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - accuracy: 0.9137 - loss: 0.7114\n",
      "Epoch 15/20\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 58ms/step - accuracy: 0.9797 - loss: 0.1815\n",
      "Epoch 16/20\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 67ms/step - accuracy: 0.9976 - loss: 0.0192\n",
      "Epoch 17/20\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 0.9982 - loss: 0.0282\n",
      "Epoch 18/20\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 58ms/step - accuracy: 0.9945 - loss: 0.0448\n",
      "Epoch 19/20\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 65ms/step - accuracy: 0.9910 - loss: 0.0693\n",
      "Epoch 20/20\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - accuracy: 0.9975 - loss: 0.0142\n",
      "Your model has reached the desired accuracy after 20epochs\n",
      "The metric was correctly defined.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import load_img,img_to_array\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import optimizers,losses\n",
    "\n",
    "base_dir='../Tensorflow'\n",
    "happy_dir=os.path.join(base_dir,'face_classification/happy_person_face')\n",
    "sad_dir=os.path.join(base_dir,'face_classification/sad_person_face')\n",
    "\n",
    "sample_image=load_img(f'{os.path.join(happy_dir,os.listdir(happy_dir)[0])}')\n",
    "sample_array=img_to_array(sample_image)\n",
    "print(f'Each image shape is:{sample_array.shape}')\n",
    "print(f'The maximum pixel value used is:{np.max(sample_array)}')\n",
    "\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self,epoch,logs=None):\n",
    "        if logs.get('accuracy') is not None and logs.get('accuracy')>0.999:\n",
    "            print('Reached 99.9% accuracy so cancelling training! ')\n",
    "            self.model.stop_training=True\n",
    "\n",
    "\n",
    "def image_generator():\n",
    "    train_datagen=ImageDataGenerator(rescale=1/255)\n",
    "    train_generator=train_datagen.flow_from_directory(directory='./Tensorflow/face_classification',\n",
    "                                                      target_size=(150,150),\n",
    "                                                      batch_size=5,\n",
    "                                                      class_mode='binary')\n",
    "    return train_generator\n",
    "\n",
    "gen=image_generator()\n",
    "\n",
    "\n",
    "def train_happy_or_sad_model(train_generator):\n",
    "\n",
    "    callbacks=myCallback()\n",
    "    model=tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Conv2D(16,(3,3),activation='relu',input_shape=(150,150, 3)),\n",
    "        tf.keras.layers.MaxPooling2D((2,2)),\n",
    "        tf.keras.layers.Conv2D(32,(3,3),activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D((2,2)),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(64,activation='relu'),\n",
    "        tf.keras.layers.Dense(1,activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.001),metrics=['accuracy'])\n",
    "\n",
    "    history=model.fit(train_generator,epochs=20,callbacks=[callbacks])\n",
    "\n",
    "    return history\n",
    "\n",
    "hist=train_happy_or_sad_model(gen)\n",
    "\n",
    "print(f'Your model has reached the desired accuracy after {len(hist.epoch)}epochs')\n",
    "\n",
    "if 'accuracy' in hist.history:\n",
    "    print(\"The metric was correctly defined.\")\n",
    "else:\n",
    "    print('Accuracy is not a valid metric')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
